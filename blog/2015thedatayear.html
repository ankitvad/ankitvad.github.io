<html>
  <head>
    <meta charset=utf-8>
    <title>Blog |-Ankit Vadehra</title>
    <link rel="stylesheet" href="style.css" type="text/css">
   </head>
  <body>
    <div class=container>
      <div class=header>
        <a href="http://ankit-vadehra.co.nr/">Ankit Vadehra</a> (Thoughts and Musings.)
      </div>
      <div class=navigation>
        <ul>
          <li><a href="/blog/blog.html">blog</a>
          <li><a href="/blog/projects.html">projects</a>
          </ul>
      </div>
      <div class=body>
      <!--Enter Title in Line(21). Date on Line(24) Content on(27)-->
  <h1 class="title">
2015 The Data Year
  </h1>
  <p class=date>written on 
22/01/2015
  </p>
  <p><!--Content after this-->
There was a posting on Data Tau, the start of January 2015. <a href="http://www.teamleada.com/">TeamLeada</a> <a href="http://www.teamleada.com/data-year">New Year Data Science</a> 2015 resolution. Every 2 weeks a new Data Science hack to perform. Now, December 2014 i successfully managed to complete 2 courses in the <a href="https://www.coursera.org/specialization/jhudatascience/">John Hopkins Data Science</a> specialization on Coursera. While it was fun and i did want to finish the other courses in the specialization, what with them being only 4 weeks long each, i was too busy once my normal semester started. Boring classes, individual projects and stuff. So, i did cancel the 3<sup>rd</sup> course i was enrolled in and decided to go along with the TeamLeda Data Hacks, since they would allow me to play with th R-Programming language some more. <br>
<h2>The First Data Set...</h2>
The mail came on the 7<sup>th</sup> of January.
<pre>You just made your 2015 New Year's resolution to improve your data analysis skills and become data literate!

Every two weeks, we will e-mail you a dataset and some problems to work on. You can use any tool you'd like, although we suggest using R or Python. R is easy to install and if you are new to programming, the Introduction to R lesson is free in our courses!

Here's the first dataset and problem! Answers will be released at a later date. Tweet your solution @LeadaHQ!</pre>
The mail had a DataSet attached to it. A CSV of a Bicycle Rental Company in California. The CSV had the following columns to it:<br>
<table border=1>
<tr>
<td>Trip ID</td>
<td>Duration</td>
<td>Start Date<td>
<td>Start Station</td>
<td>Start Terminal</td></tr>
<tr><td>End Date</td>
<td>End Station</td>
<td>End Terminal</td>
<td>Bike #</td>
<td>Subscription Type</td>
<td>Zip Code</td></tr>
</table>
<h2>The Problems</h2>
The problems this particular Data Set provided were, as follows:
<pre>Problem 1: What was the average total time (in minutes) used by a bicycle in the data?

Problem 2: What was the most popular day by trip frequency in this dataset?

Problem 3 (harder): Assuming there are 30 bikes per station, find what date and time the bikes FIRST need to be rebalanced. As in, there are 0 bikes at a terminal for a customer to rent.</pre>
<h2>The First Problem</h2>
This one was particularly easy. Now the Data Set provided the time each cycle was issued/borrowed in seconds, also, each bike once returned, was reissued and had other records too. Now according to the Question, we needed the average time of all the bicycles(..individually) and in minutes. Now the CSV's 2<sup>nd</sup> Column:"Duration" and the 9<sup>th</sup> Column:"Bike #" was what was required. So, the code:
<pre><code>(sum(x[,2])/60)/(length(unique(x[,9])))</pre></code>
What this does, in it's entire-ty is: divide the "sum of total" durations by 60. This gives the total borrowing time in minutes. Now we just need the average. So, divide the former value by the number of unique bi-cycles that were issued/lent. Easy Peasy !
<pre><code><b>Answer: 4288.087</b></pre></code>
<h2>The Second Problem</h2>
This one wasn't that easy. The problem, easy. What to do? Simple, check the date and see the date with the maximum number of rentals. That's the trip frequency for you. The BIGGEST problem, the 3<sup>rd</sup> column which took care of the Start Date was in form of a string and also contained the Time. Hence, i couldn't just use the unique() function again. So, what to do next? Copy the CSV in another variable. Remove the time from the back, so that only the Date remains.
<pre><code>str(y)
i<-sapply(y,is.factor)
y[i]<-lapply(y[i],as.character)
head(y)
str(y)

poop <- function(y){
  for(i in 1:144015){
    dts=y[i,3]
    count=nchar(dts,type="char")
    fifthletter=substr(dts,count-4,count-4)
    if(fifthletter==" "){
      update=substr(dts,1,count-5)
     }else{
        update=substr(dts,1,count-6)
      }
    y[i,3]=update
  }
  return(y)
}

calcfreq<-function(check,alldates,count=1){
  for(i in 1:184){
    count[i]=nrow(subset(check,check[,3]==alldates[i]))
  }
  return(count)
}</pre></code>
This gives the plain date. After that, simple. Calculate the Frequency.
<pre><code><b>Answer: 
> count[28]
[1] 1264
> alldates[28]
[1] "9/25/13"
</b></pre></code>
<h2>The Third Problem</h2>
This has something to do with keeping a buffer to check when the bike is out and when it is returned. But, i have no idea to do this. So... leave it. Time for the 2<sup>nd</sup> DataSet now.
 
    



  

  </p>
  </div>
  <div class=footer>
    <p>Blog Powered using <a href="">CaffeinePost</a></p>
    <p>You can find me at:</p>
    <p><a href="http://github.com/ankitvad">GitHub</a>, <a href="http://www.linkedin.com/in/ankitvad">LinkedIn</a>, <a href="https://www.facebook.com/ankit.vadehra">Facebook</a>,<br><a href="https://plus.google.com/+AnkitVadehr%C4%81">Google+</a>, <a href="http://www.quora.com/Ankit-Vadehra">Quora</a>, <a href="http://www.twitter.com/ankitvad">Twitter</a></p>
  </div>
  </div>
  </body>
</html>
